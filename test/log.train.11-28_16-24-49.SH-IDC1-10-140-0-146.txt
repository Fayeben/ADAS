2022-11-28 16:24:49,644 xmuda INFO: 1 GPUs available
2022-11-28 16:24:49,645 xmuda INFO: Namespace(config_file='/mnt/petrelfs/feiben/ADAS-git/configs/a2d2_semantic_kitti/sampling.yaml', opts=['OUTPUT_DIR', '/mnt/petrelfs/feiben/ADAS-git/test'])
2022-11-28 16:24:49,646 xmuda INFO: Loaded configuration file /mnt/petrelfs/feiben/ADAS-git/configs/a2d2_semantic_kitti/sampling.yaml
2022-11-28 16:24:49,647 xmuda INFO: Running with config:
AUTO_RESUME: True
DATALOADER:
  DROP_LAST: True
  NUM_WORKERS: 4
DATASET_SOURCE:
  A2D2SCN:
    augmentation:
      color_jitter: (0.4, 0.4, 0.4)
      flip_y: 0.5
      fliplr: 0.5
      noisy_rot: 0.1
      rot_z: 6.2831
      transl: True
    full_scale: 4096
    image_normalizer: ()
    merge_classes: True
    preprocess_dir: audi/a2d2_preprocess
    resize: (480, 302)
    scale: 20
    use_image: True
  SETTING: audi2kitti
  TRAIN: ('train',)
  TYPE: A2D2SCN
DATASET_TARGET:
  SemanticKITTISCN:
    augmentation:
      bottom_crop: (480, 302)
      color_jitter: (0.4, 0.4, 0.4)
      flip_y: 0.5
      fliplr: 0.5
      noisy_rot: 0.1
      rot_z: 6.2831
      transl: True
    full_scale: 4096
    image_normalizer: ()
    merge_classes: True
    preprocess_dir: semantickiiti-preposses/preprocess
    pselab_paths: ()
    scale: 20
    semantic_kitti_dir: s3://feiben/semantickitti-dataset/
  TEST: ('test',)
  TRAIN: ('train',)
  TYPE: SemanticKITTISCN
  VAL: ('val',)
MODEL:
  TYPE: 
MODEL_2D:
  CKPT_PATH: 
  DUAL_HEAD: False
  NUM_CLASSES: 10
  TYPE: UNetResNet34
  UNetResNet34:
    pretrained: True
MODEL_3D:
  CKPT_PATH: 
  DUAL_HEAD: False
  NUM_CLASSES: 10
  SCN:
    block_reps: 1
    full_scale: 4096
    in_channels: 1
    m: 16
    num_planes: 7
    residual_blocks: False
  TYPE: SCN
OPTIMIZER:
  Adam:
    betas: (0.9, 0.999)
  BASE_LR: 0.001
  TYPE: Adam
  WEIGHT_DECAY: 0.0
OUTPUT_DIR: /mnt/petrelfs/feiben/ADAS-git/test
RESUME_PATH: 
RESUME_STATES: True
RNG_SEED: 1
SCHEDULER:
  CLIP_LR: 0.0
  MAX_ITERATION: 150000
  MultiStepLR:
    gamma: 0.1
    milestones: (80000, 90000, 100000, 110000, 120000, 1400000)
  TYPE: MultiStepLR
TRAIN:
  BATCH_SIZE: 1
  CHECKPOINT_PERIOD: 5000
  CLASS_WEIGHTS: [1.89090012, 2.0585112, 3.1970535, 3.1111633, 1.0, 2.93751704, 1.92053733, 1.47886874, 1.04654198, 1.78266561]
  FROZEN_PATTERNS: ()
  LOG_PERIOD: 50
  MAX_TO_KEEP: 100
  SUMMARY_PERIOD: 1000
  XMUDA:
    lambda_logcoral: 0.0
    lambda_minent: 0.0
    lambda_pl: 0.0
    lambda_xm_src: 0.1
    lambda_xm_trg: 0.01
VAL:
  BATCH_SIZE: 1
  LOG_PERIOD: 20
  METRIC: seg_iou
  PERIOD: 5000
2022-11-28 16:24:56,196 xmuda.train INFO: Build 2D model:
Net2DSeg(
  (net_2d): UNetResNet34(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (dec_t_conv_stage5): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_conv_stage4): Sequential(
      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_t_conv_stage4): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_conv_stage3): Sequential(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_t_conv_stage3): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_conv_stage2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_t_conv_stage2): Sequential(
      (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dec_conv_stage1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
2022-11-28 16:24:56,215 xmuda.train INFO: Build 3D model:
Net3DSeg(
  (net_3d): UNetSCN(
    (sparseModel): Sequential(
      (0): InputLayer()
      (1): SubmanifoldConvolution 1->16 C3
      (2): Sequential(
        (0): Sequential(
          (0): BatchNormLeakyReLU(16,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
          (1): SubmanifoldConvolution 16->16 C3
        )
        (1): ConcatTable(
          (0): Identity()
          (1): Sequential(
            (0): BatchNormLeakyReLU(16,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
            (1): Convolution 16->32 C2/2
            (2): Sequential(
              (0): Sequential(
                (0): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                (1): SubmanifoldConvolution 32->32 C3
              )
              (1): ConcatTable(
                (0): Identity()
                (1): Sequential(
                  (0): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                  (1): Convolution 32->48 C2/2
                  (2): Sequential(
                    (0): Sequential(
                      (0): BatchNormLeakyReLU(48,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                      (1): SubmanifoldConvolution 48->48 C3
                    )
                    (1): ConcatTable(
                      (0): Identity()
                      (1): Sequential(
                        (0): BatchNormLeakyReLU(48,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                        (1): Convolution 48->64 C2/2
                        (2): Sequential(
                          (0): Sequential(
                            (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                            (1): SubmanifoldConvolution 64->64 C3
                          )
                          (1): ConcatTable(
                            (0): Identity()
                            (1): Sequential(
                              (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                              (1): Convolution 64->80 C2/2
                              (2): Sequential(
                                (0): Sequential(
                                  (0): BatchNormLeakyReLU(80,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                  (1): SubmanifoldConvolution 80->80 C3
                                )
                                (1): ConcatTable(
                                  (0): Identity()
                                  (1): Sequential(
                                    (0): BatchNormLeakyReLU(80,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                    (1): Convolution 80->96 C2/2
                                    (2): Sequential(
                                      (0): Sequential(
                                        (0): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                        (1): SubmanifoldConvolution 96->96 C3
                                      )
                                      (1): ConcatTable(
                                        (0): Identity()
                                        (1): Sequential(
                                          (0): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                          (1): Convolution 96->112 C2/2
                                          (2): Sequential(
                                            (0): Sequential(
                                              (0): BatchNormLeakyReLU(112,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                              (1): SubmanifoldConvolution 112->112 C3
                                            )
                                          )
                                          (3): BatchNormLeakyReLU(112,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                          (4): Deconvolution 112->96 C2/2
                                        )
                                      )
                                      (2): JoinTable()
                                      (3): Sequential(
                                        (0): BatchNormLeakyReLU(192,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                        (1): SubmanifoldConvolution 192->96 C3
                                      )
                                    )
                                    (3): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                    (4): Deconvolution 96->80 C2/2
                                  )
                                )
                                (2): JoinTable()
                                (3): Sequential(
                                  (0): BatchNormLeakyReLU(160,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                                  (1): SubmanifoldConvolution 160->80 C3
                                )
                              )
                              (3): BatchNormLeakyReLU(80,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                              (4): Deconvolution 80->64 C2/2
                            )
                          )
                          (2): JoinTable()
                          (3): Sequential(
                            (0): BatchNormLeakyReLU(128,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                            (1): SubmanifoldConvolution 128->64 C3
                          )
                        )
                        (3): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                        (4): Deconvolution 64->48 C2/2
                      )
                    )
                    (2): JoinTable()
                    (3): Sequential(
                      (0): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                      (1): SubmanifoldConvolution 96->48 C3
                    )
                  )
                  (3): BatchNormLeakyReLU(48,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                  (4): Deconvolution 48->32 C2/2
                )
              )
              (2): JoinTable()
              (3): Sequential(
                (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
                (1): SubmanifoldConvolution 64->32 C3
              )
            )
            (3): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
            (4): Deconvolution 32->16 C2/2
          )
        )
        (2): JoinTable()
        (3): Sequential(
          (0): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.99,affine=True,leakiness=0)
          (1): SubmanifoldConvolution 32->16 C3
        )
      )
      (3): BatchNormReLU(16,eps=0.0001,momentum=0.99,affine=True)
      (4): OutputLayer()
    )
  )
  (linear): Linear(in_features=16, out_features=10, bias=True)
)
2022-11-28 16:24:57,679 xmuda.train INFO: Loading checkpoint from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_2d_100000.pth, MD5: 7132674fa505a226ac1667fe85a548cf
2022-11-28 16:24:57,807 xmuda.train INFO: Loading optimizer from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_2d_100000.pth
2022-11-28 16:24:57,880 xmuda.train INFO: Loading scheduler from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_2d_100000.pth
2022-11-28 16:24:58,037 xmuda.train INFO: Loading checkpoint from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_3d_075000.pth, MD5: 74147c02ae6cc18018eda7a2721d62f1
2022-11-28 16:24:58,060 xmuda.train INFO: Loading optimizer from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_3d_075000.pth
2022-11-28 16:24:58,080 xmuda.train INFO: Loading scheduler from /mnt/lustre/feiben/xmuda/a2d2_semantic_kitti/baseline/model_3d_075000.pth
2022-11-28 16:24:58,080 xmuda.train INFO: No checkpoint found. Initializing model from scratch
2022-11-28 16:26:05,430 xmuda.train INFO: Start training from iteration 100000
